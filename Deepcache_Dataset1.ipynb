{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMbYAqjrEsb8oLURrHXd6u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('Datasets/syntheticDataset_O50.csv') # 데이터 불러오기\n",
        "\n",
        "df['hour'] = df['request_time'] // 3600  # 초 단위 -> 시간 단위 버킷\n",
        "\n",
        "object_ids = df['object_ID'].unique()\n",
        "object_ids.sort()\n",
        "num_objects = len(object_ids)\n",
        "print(\"총 객체 수: \", num_objects)\n",
        "\n",
        "pivot = df.groupby(['hour', 'object_ID']).size().unstack(fill_value=0)\n",
        "pivot = pivot.reindex(columns=object_ids, fill_value=0) # 객체 ID 순서 맞추기\n",
        "\n",
        "# 확률 벡터로 정규화\n",
        "probs = pivot.div(pivot.sum(axis=1), axis=0).fillna(0)\n",
        "\n",
        "m, K = 20, 10\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(probs) - m - K):\n",
        "  x_seq = probs.iloc[i:i+m].values  # shape: (m, d)\n",
        "  x_next = probs.iloc[i+m:i+m+K].values\n",
        "  X.append(x_seq)\n",
        "  y.append(x_next)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X.shape =\", X.shape)\n",
        "print(\"y.shape =\", y.shape)"
      ],
      "metadata": {
        "id": "x8i71sMFV_w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61b8a2f-e0b8-42c2-d5ec-93cd9252fa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 객체 수:  50\n",
            "X.shape = (55, 20, 50)\n",
            "y.shape = (55, 10, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 예측 모델\n",
        "# 과거 일정 시간 동안의 요청 분포를 받아서 앞으로의 일정 시간 동안의 요청 분포를 예측하는 구조\n",
        "# Encoder: 과거 m시간 동안의 요청 분포((m, 1033) 시퀀스)를 받아서, 마지막 hidden state와 cell state로 응축된 정보를 생성 -> context vector로 요약\n",
        "# Decoder: Encoder에서 받은 context vector를 바탕으로, 앞으로 k시간 동안 어떤 객체들이 얼마나 요청될지를 시퀀스 형태로 한 시간씩 예측\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, RepeatVector\n",
        "\n",
        "def build_seq2seq_model(m, K, num_objects):\n",
        "  # ----- Encoder -----\n",
        "  encoder_inputs = Input(shape=(m, num_objects)) # (batch, m(시간), num_objects(객체수))\n",
        "  encoder_lstm = LSTM(128, return_state=True) # LSTM이 마지막 시점의 hidden state와 cell state를 반환\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs) # state_h와 state_c는 Decoder의 초기 상태로 사용됨\n",
        "  encoder_states = [state_h, state_c] # Encoder의 상태를 Decoder에 전달하기 위해 리스트로 묶음\n",
        "\n",
        "  # ----- Decoder -----\n",
        "  decoder_inputs = RepeatVector(K)(encoder_outputs) # (batch, K, 128): Encoder의 마지막 출력을 K번 복제해서 Decoder 입력으로 사용, Decoder는 K시간 동안 예측을 수행\n",
        "  decoder_lstm = LSTM(128, return_sequences=True) # LSTM의 hidden size는 64, return_sequences=True는 각 시점마다 출력을 반환\n",
        "  decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "  # 객체별 확률 예측 (각 시점당 num_objects 개 출력)\n",
        "  decoder_dense = TimeDistributed(Dense(num_objects, activation='softmax')) # softmax는 확률 분포로 만들어줌\n",
        "  output_seq = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # ----- 모델 구성 -----\n",
        "  model = Model(encoder_inputs, output_seq)\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "\n",
        "num_objects = 50  # 객체 수\n",
        "m = 20              # 과거 시간: 입력 시퀀스 길이\n",
        "K = 10             # 미래 시간: 출력 시퀀스 길이\n",
        "\n",
        "model = build_seq2seq_model(m, K, num_objects)\n",
        "\n",
        "# 데이터: X shape = (samples, 20, 50), y shape = (samples, 10, 50)\n",
        "history = model.fit(X, y, epochs=30, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 학습 후 추론 코드\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 시퀀스 데이터를 학습/검증/테스트로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 학습 시에도 X_train, y_train 사용\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 추론 (예측)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"예측 결과 형태:\", y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWBu2M4GXrZv",
        "outputId": "1fc41b3e-611a-40c6-ccde-a43910e0f2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - loss: 8.4627e-04 - mae: 0.0141 - val_loss: 0.0013 - val_mae: 0.0130\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 8.2983e-04 - mae: 0.0140 - val_loss: 0.0013 - val_mae: 0.0130\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 8.5760e-04 - mae: 0.0142 - val_loss: 0.0013 - val_mae: 0.0130\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 8.8486e-04 - mae: 0.0144 - val_loss: 0.0013 - val_mae: 0.0129\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 8.6540e-04 - mae: 0.0143 - val_loss: 0.0013 - val_mae: 0.0129\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 8.6730e-04 - mae: 0.0143 - val_loss: 0.0013 - val_mae: 0.0129\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 8.2528e-04 - mae: 0.0140 - val_loss: 0.0013 - val_mae: 0.0128\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 8.3814e-04 - mae: 0.0141 - val_loss: 0.0013 - val_mae: 0.0128\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 8.4622e-04 - mae: 0.0142 - val_loss: 0.0012 - val_mae: 0.0128\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 8.6834e-04 - mae: 0.0144 - val_loss: 0.0012 - val_mae: 0.0127\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 8.2834e-04 - mae: 0.0140 - val_loss: 0.0012 - val_mae: 0.0126\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 7.8568e-04 - mae: 0.0139 - val_loss: 0.0012 - val_mae: 0.0124\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 7.9552e-04 - mae: 0.0139 - val_loss: 0.0012 - val_mae: 0.0122\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 7.5854e-04 - mae: 0.0138 - val_loss: 0.0012 - val_mae: 0.0117\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 6.9544e-04 - mae: 0.0134 - val_loss: 0.0012 - val_mae: 0.0119\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 6.9138e-04 - mae: 0.0135 - val_loss: 0.0013 - val_mae: 0.0123\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 7.0676e-04 - mae: 0.0135 - val_loss: 0.0012 - val_mae: 0.0120\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6.5973e-04 - mae: 0.0134 - val_loss: 0.0012 - val_mae: 0.0120\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 6.5455e-04 - mae: 0.0133 - val_loss: 0.0012 - val_mae: 0.0121\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 6.4333e-04 - mae: 0.0132 - val_loss: 0.0012 - val_mae: 0.0123\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.2955e-04 - mae: 0.0131 - val_loss: 0.0012 - val_mae: 0.0128\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 6.2333e-04 - mae: 0.0132 - val_loss: 0.0013 - val_mae: 0.0135\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 5.9886e-04 - mae: 0.0130 - val_loss: 0.0013 - val_mae: 0.0134\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 5.7629e-04 - mae: 0.0129 - val_loss: 0.0012 - val_mae: 0.0132\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 5.6067e-04 - mae: 0.0127 - val_loss: 0.0013 - val_mae: 0.0135\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.3973e-04 - mae: 0.0126 - val_loss: 0.0014 - val_mae: 0.0144\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.2202e-04 - mae: 0.0123 - val_loss: 0.0015 - val_mae: 0.0149\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 5.0339e-04 - mae: 0.0121 - val_loss: 0.0013 - val_mae: 0.0139\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 4.8274e-04 - mae: 0.0118 - val_loss: 0.0013 - val_mae: 0.0140\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 4.9057e-04 - mae: 0.0118 - val_loss: 0.0017 - val_mae: 0.0160\n",
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 6.6218e-04 - mae: 0.0122 - val_loss: 4.1591e-04 - val_mae: 0.0113\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 6.3273e-04 - mae: 0.0120 - val_loss: 4.2309e-04 - val_mae: 0.0113\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 6.1551e-04 - mae: 0.0118 - val_loss: 4.0050e-04 - val_mae: 0.0107\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 6.2727e-04 - mae: 0.0118 - val_loss: 4.9930e-04 - val_mae: 0.0109\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 6.5460e-04 - mae: 0.0119 - val_loss: 3.6581e-04 - val_mae: 0.0106\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.8569e-04 - mae: 0.0115 - val_loss: 4.1102e-04 - val_mae: 0.0109\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 5.9973e-04 - mae: 0.0116 - val_loss: 3.4127e-04 - val_mae: 0.0103\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.6003e-04 - mae: 0.0113 - val_loss: 3.4078e-04 - val_mae: 0.0100\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.6136e-04 - mae: 0.0111 - val_loss: 3.2836e-04 - val_mae: 0.0101\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.8655e-04 - mae: 0.0109 - val_loss: 3.6106e-04 - val_mae: 0.0105\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.5674e-04 - mae: 0.0112 - val_loss: 3.2490e-04 - val_mae: 0.0101\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.8056e-04 - mae: 0.0107 - val_loss: 3.4506e-04 - val_mae: 0.0098\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 5.3322e-04 - mae: 0.0108 - val_loss: 3.1686e-04 - val_mae: 0.0099\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 5.1246e-04 - mae: 0.0107 - val_loss: 3.3321e-04 - val_mae: 0.0102\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 5.1685e-04 - mae: 0.0108 - val_loss: 3.0959e-04 - val_mae: 0.0096\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 4.6074e-04 - mae: 0.0105 - val_loss: 3.0583e-04 - val_mae: 0.0097\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 4.5133e-04 - mae: 0.0104 - val_loss: 3.1671e-04 - val_mae: 0.0098\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 4.6869e-04 - mae: 0.0104 - val_loss: 3.1911e-04 - val_mae: 0.0093\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 4.7867e-04 - mae: 0.0105 - val_loss: 3.2642e-04 - val_mae: 0.0097\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4941e-04 - mae: 0.0105 - val_loss: 3.0112e-04 - val_mae: 0.0092\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.6653e-04 - mae: 0.0103 - val_loss: 2.8526e-04 - val_mae: 0.0090\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.3859e-04 - mae: 0.0102 - val_loss: 2.8241e-04 - val_mae: 0.0092\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 4.3277e-04 - mae: 0.0101 - val_loss: 2.6930e-04 - val_mae: 0.0087\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 4.3346e-04 - mae: 0.0098 - val_loss: 2.5849e-04 - val_mae: 0.0088\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 4.0518e-04 - mae: 0.0096 - val_loss: 2.7725e-04 - val_mae: 0.0091\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - loss: 3.9463e-04 - mae: 0.0096 - val_loss: 2.5355e-04 - val_mae: 0.0084\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 4.0605e-04 - mae: 0.0094 - val_loss: 2.6456e-04 - val_mae: 0.0086\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.8725e-04 - mae: 0.0094 - val_loss: 2.5080e-04 - val_mae: 0.0083\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 3.7196e-04 - mae: 0.0092 - val_loss: 2.3249e-04 - val_mae: 0.0082\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 3.7085e-04 - mae: 0.0092 - val_loss: 2.9165e-04 - val_mae: 0.0090\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "예측 결과 형태: (11, 10, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 캐시 정책 구현\n",
        "# 예측 결과를 기반으로 DeepCache의 캐싱 정책을 구현하고 이를 통해 기본 캐싱 전략과 비교평가\n",
        "M = 5 # 캐시에 넣을 상위 M개 객체\n",
        "top_objects_each_t = []\n",
        "\n",
        "# 예측 결과에서 Top-M 객체 추출\n",
        "for i in range(len(y_pred)):\n",
        "    for t in range(K - 1):    # t+1 예측을 위해 K-1까지만\n",
        "        next_probs = y_pred[i, t+1]  # 다음 시점 확률 분포\n",
        "        top_indices = next_probs.argsort()[-M:][::-1]  # 상위 M개 객체 인덱스\n",
        "        top_objects_each_t.append(top_indices)\n",
        "\n",
        "# 실제 요청 로그 준비\n",
        "actual_requests = df.sort_values('request_time')['object_ID'].tolist()"
      ],
      "metadata": {
        "id": "UVbuP8OZZDSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 캐시 시뮬레이션 (LRU + 예측 기반) -> 성능 평가\n",
        "from collections import deque\n",
        "\n",
        "CACHE_SIZE = 20\n",
        "cache = deque(maxlen=CACHE_SIZE)\n",
        "hit = 0\n",
        "total = 0\n",
        "fake_insert_idx = 0\n",
        "\n",
        "for t, req in enumerate(actual_requests):\n",
        "  # 예측한 객체를 먼저 캐시에 넣기\n",
        "  if t % 100 == 0 and fake_insert_idx < len(top_objects_each_t):\n",
        "    fake_objs = top_objects_each_t[fake_insert_idx]\n",
        "    for obj in fake_objs:\n",
        "      if obj not in cache:\n",
        "        cache.append(obj)\n",
        "    fake_insert_idx += 1\n",
        "\n",
        "  total += 1\n",
        "  if req in cache:\n",
        "    hit += 1\n",
        "  else:\n",
        "    cache.append(req)\n",
        "\n",
        "print(f\"DeepCache 기반 캐시 hit ratio: {hit / total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKL9SlGBmjXX",
        "outputId": "93c15755-437c-4d00-f160-02a2f8c599e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepCache 기반 캐시 hit ratio: 0.6571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 LRU 캐시와 성능 비교"
      ],
      "metadata": {
        "id": "wDg2rcihoHav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}